# -*- coding: utf-8 -*-
"""Forage_Quantium_DA_test1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Evg2qhoDYX8XMT7POyy0sboCXmUespUS

### Forage_Quantium_DA Project By Yongshi Lin
"""

import pandas as pd
import re
from collections import Counter
import seaborn as sns
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

"""#Import 2 datasets and do data cleaning:"""

pb = pd.read_csv("/content/QVI_purchase_behaviour.csv")
pb = pb.dropna()  #drop null values
pb.head()

print(pb.shape)

td = pd.read_excel("/content/QVI_transaction_data.xlsx")
td = td.dropna()  #drop null values

# Function to convert Excel serial date to datetime
def excel_date_to_datetime(excel_date):
    return datetime(1899, 12, 30) + timedelta(days=int(excel_date))

td['DATE'] = td['DATE'].apply(excel_date_to_datetime)

td.head()

td.shape

"""#Merge datasets and get overview:"""

merge_df = td.merge(pb, how = 'left', on = 'LYLTY_CARD_NBR')

# Extracting brand name (assume the first word) from the prod_name and make a new column as 'BRAND'
merge_df['BRAND'] = merge_df['PROD_NAME'].apply(lambda x: x.split()[0])

# Extracting package size from the prod_name and make a new column as 'PACK_SIZE'
merge_df['PACK_SIZE'] = merge_df['PROD_NAME'].str.extract(r'(\d+g)', expand=False)

# Extracting flavor from the prod_name and make a new column as 'FAVOR'
merge_df['FLAVOR'] = merge_df['PROD_NAME'].str.extract(r'(\b\w+(?=\s\d+g))', expand=False)

merge_df.head()
merge_df.to_csv('QVI_merge_dataset.csv')  #save as csv file

merge_df.columns

merge_df.shape

# Check if some customers were not matched on by checking for nulls
print(merge_df['LIFESTAGE'].isnull().sum())
print(merge_df['PREMIUM_CUSTOMER'].isnull().sum())

"""### Product Text Analysis to focus on chips




"""

# Extract unique product names
unique_prod_names = merge_df['PROD_NAME'].unique()

# Split to individual words
prod_words = []
for name in unique_prod_names:
    prod_words.extend(re.split(r'\s+', name))

# Filter out words containing digits
prod_words = [i for i in prod_words if not re.search(r'\d', i)]

# Filter out words without alphabetic characters
prod_words = [i for i in prod_words if re.search(r'[a-zA-Z]', i)]

# Count the words
word_count = Counter(prod_words)
print(word_count)

# OR Count the key words in product names and sort them
prod_words_series = pd.Series(prod_words)
word_counts = prod_words_series.value_counts(sort=True)
word_counts

# Sort the key words in English alphabetical order
sorted_words = sorted(word_counts.index)
print(sorted_words)

"""### Trends and Insights (for all)"""

total_sales_sum = merge_df['TOT_SALES'].sum()
total_sales_mean = merge_df['TOT_SALES'].mean()
total_sales_median = merge_df['TOT_SALES'].median()
print(f"Total Sales Sum: {total_sales_sum}")
print(f"Total Sales Mean: {total_sales_mean}")
print(f"Total Sales Median: {total_sales_median}")

# Highest sales by LIFESTAGE
sales_by_lifestage = merge_df.groupby('LIFESTAGE')['TOT_SALES'].sum().sort_values(ascending=False)
print(f"Sales by LIFESTAGE: \n{sales_by_lifestage}")

# Highest sales by Customer Categories
sales_by_customers = merge_df.groupby('PREMIUM_CUSTOMER')['TOT_SALES'].sum().sort_values(ascending = False)
print(f"Sales by Customer Categories: \n{sales_by_customers}")

# Highest sales by PRODUCT NAME
sales_by_product = merge_df.groupby('PROD_NAME')['TOT_SALES'].sum().sort_values(ascending=False)
print(f"Sales by PRODUCT NAME: \n{sales_by_product}")

"""### Check for Outliers"""

outliers = merge_df[merge_df['TOT_SALES'] > 200]
print(f"Outliers: \n{outliers}")
# Insight: In store#226, a 'Premium' customer from 'Older Families' purchased 200 packs of 'Dorito Corn Chp Supreme 380g' in 2018 and 2019, contributed to 650*2=1300 dollars of sales in total.

# check if this customer buy any other products
cust226000 = merge_df[merge_df['LYLTY_CARD_NBR'] == 226000]
print(cust226000)

"""####Insight: This customer 226000 only purchased large amount of chips once a year in 2018, 2019, not like a regular retail customer. We can remove this outliner(customer) for further analysis."""

sns.set(style = 'whitegrid')
removed_outliers = merge_df[merge_df['TOT_SALES'] <= 200]
sns.boxplot(data=merge_df, x="PREMIUM_CUSTOMER", y=removed_outliers["TOT_SALES"])
plt.title('Box Plot of TOT_SALES.')
plt.show()

"""#### Insight: After removing the outliner,the total sales of different premium customers performs basicly the same. Total sales value range from [2,14], points (14, 30] consider potential outliners. The mean total sales value is 7.

#Focus on datasets only related to chip products transaction:

#### Given the substantial size of the sample, I will ensure that all the data I analyze pertains specifically to chips, excluding cheese products, chicken products, and salsa products, which cannot be reliably identified from the product names alone. The original dataset's product names are often ambiguous, making it difficult to discern product categories. Unless the stores provide prior confirmation that most of the products are indeed chips, I will use keywords highly related to chips to filter the relevant products.

#### I recommend that retail stores update their product naming conventions to include standardized categories, at least for the primary product categories. This would significantly improve the clarity and utility of the data for analysis.
"""

# identify chips products by keywords from the text analysis
chip_keywords = ["Chip", "Chips", "Chp", "Crisps", "Crips", "Crinkle", "Crnkle"]

# Function to filter products that contain any of the chip-related keywords
def is_chip_product(prod_name, keywords):
    return any(i in prod_name for i in keywords)

# Apply the function to filter the DataFrame
chips_df = merge_df[merge_df['PROD_NAME'].apply(lambda x: is_chip_product(x, chip_keywords))]

# Remove the outliner(customer226000) as we observed and analyzed already above
chips_df = chips_df[chips_df['LYLTY_CARD_NBR'] != 226000]

print(chips_df.head())

print(chips_df['BRAND'].unique())

"""#### The product brand & flavor name has repleacable keywords:"""

# replace repeated brand names
chips_df['BRAND'] = chips_df['BRAND'].replace({'Dorito':'Doritos', 'Smith':'Smiths', 'Snbts':'Sunbites', 'Infzns':'Infuzions', 'WW': 'Woolworths'})
print(chips_df['BRAND'].unique())

# replace repeated flavor names
chips_df['FLAVOR'] = chips_df['FLAVOR'].replace({'Chilli':'Chili', 'Onin':'Onion', 'OnionDip':'Onion', 'saltd': 'Salt', 'Salted': 'Salt', 'BBQ':'Barbecue'})
# fill in unknown flavor
chips_df['FLAVOR'] = chips_df['FLAVOR'].replace({'Chips':'unknown', 'Crips':'unknown', 'Crisps':'unknown', 'Bag': 'unknown', 'Supreme':'unknown'})
# fill in NaN to unkown flavor
chips_df['FLAVOR'] = chips_df['FLAVOR'].fillna('unknown')
print(chips_df['FLAVOR'].unique())

# Save as csv file
chips_df.to_csv('QVI_chips_transaction.csv')

"""### Data Summary"""

chips_df.describe()

"""### Number of Transactions Over Time"""

num_trans = chips_df.groupby('DATE').size()

# hold the aggregated results, count transactions per day
num_trans = num_trans.reset_index(name='Transaction Count')

num_trans.sort_values(by = 'DATE').head()

num_trans.shape

"""#### Insight: Only 364 days in a year had transaction. Let's see which date and why no transaction on that specific date."""

# Create a sequence of all dates within the range
all_dates = pd.date_range(start='2018-07-01', end='2019-06-30')
all_dates_df = pd.DataFrame({'DATE': all_dates})

# Merge with the transaction counts
transactions_by_day = pd.merge(all_dates_df, num_trans, on='DATE', how='left').fillna(0)

plt.figure(figsize=(25, 10))
sns.lineplot(data=transactions_by_day, x='DATE', y='Transaction Count', marker='o')
plt.title('Number of Transactions of Chips Over Time')
plt.ylabel('Number of Transactions')
plt.xlabel('Date')
plt.xticks(rotation=45)

# Highlight the dates where transaction count is zero
zero_trans_dates = transactions_by_day[transactions_by_day['Transaction Count'] == 0]['DATE']
for zero_date in zero_trans_dates:
    plt.axvline(x=zero_date, color='red', linestyle='--', lw=0.5)
    plt.text(zero_date, 0.1, zero_date.strftime('%y-%m-%d'), verticalalignment ='bottom')

plt.show()

"""### Sales of Chips Over Time"""

# Group by DATE and sum the SALES
sales_by_date = chips_df.groupby('DATE')['TOT_SALES'].sum().reset_index()
sales_by_date.sort_values(by = 'TOT_SALES', ascending = False).head()

plt.figure(figsize=(25, 10))
sns.lineplot(data = sales_by_date, x = 'DATE', y = 'TOT_SALES', marker = 'o')
plt.title('Sales of Chips Over Time')
plt.ylabel('Total Sales')
plt.xlabel('Date')
plt.show()

"""#### Insight: Only 1 day there was no transaction happened, which is on Dec 25, 2018, Christmas Day. We can assume that the stores closed on this holiday date, which is normal. Also, the day before Christmas Day had the peak number of transaction and the peak total sales of chips, which shows the customer purchasing behavior.

### Total Sales Distribution
"""

sns.histplot(chips_df['TOT_SALES'], bins =20, kde=True)
plt.title('Total Sales Distribution')
plt.xlabel('Total Sales')
plt.ylabel('Frequency')

# Adjust x-axis limits
plt.xlim(0, 50)  # Set the limit according the data distribution

plt.show()

"""#### Insight: Customers mostly spend 4-13 dollars for chips per transaction.

### Sales by Product Category
"""

# Group by PROD_NAME and sum the SALES
sales_prod_name = chips_df.groupby('PROD_NAME')['TOT_SALES'].sum().reset_index()
sales_prod_name.sort_values(by = 'TOT_SALES', ascending = False).head()

"""# Customer Behavior

## Sales by Customer Lifestage & Category
"""

plt.figure(figsize=(8, 6))
# Total sales by LIFESTAGE and PREMIUM_CUSTOMER
cust_sales = chips_df.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['TOT_SALES'].sum().reset_index()

# Calculate total sales to get proportions
total_sales = cust_sales['TOT_SALES'].sum()
cust_sales['Proportion'] = cust_sales['TOT_SALES'] / total_sales

# Using seaborn's catplot to create a bar plot
g = sns.catplot(
    data=cust_sales,
    x='LIFESTAGE', y='Proportion', hue='PREMIUM_CUSTOMER',
    kind='bar', height=6, aspect=2
)

g.set_axis_labels("Lifestage", "Proportion of Total Sales")
g.fig.suptitle('Proportion of Sales by Lifestage and Premium Customer', fontsize=16)
g.set_xticklabels(rotation=90)

# Adding text labels with proportion percentages
for ax in g.axes.flat:
    for p in ax.patches:
      if p.get_height() > 0:
        ax.annotate(f'{p.get_height():.2%}', (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),
                    textcoords='offset points')

plt.show()

"""#### Insight: Budget - Older Families takes up the largest proporation of sales. Second is Mainstream - Retirees; third is Mainstream - Young Singles/Couples.

### Analyze the Brands Preference of the Top Customer Group Buyers (Brand Affinity)

*1) Budget - Older Families:*
"""

# filter data for the target group 1(Budget - Older Families)
segment1 = chips_df[(chips_df['LIFESTAGE'] == 'OLDER FAMILIES') & (chips_df['PREMIUM_CUSTOMER'] == 'Budget')]
others1 = chips_df[~(chips_df['LIFESTAGE'] == 'OLDER FAMILIES') & (chips_df['PREMIUM_CUSTOMER'] == 'Budget')]

# caculate brand proporation for the target group
qty_sg1 = segment1['PROD_QTY'].sum()
brand_qty_sg1 = segment1.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_sg1['target_proportion'] = brand_qty_sg1['PROD_QTY'] / qty_sg1

# caculate brand proporation for the rest of the population
qty_others1 = others1['PROD_QTY'].sum()
brand_qty_others1 = others1.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_others1['others_proportion'] = brand_qty_others1['PROD_QTY'] / qty_others1

# compare proporations
brand_compar1 = pd.merge(brand_qty_sg1[['BRAND', 'target_proportion']],
                         brand_qty_others1[['BRAND', 'others_proportion']],
                         on = 'BRAND', how = 'outer').fillna(0)
brand_compar1['affinity'] = brand_compar1['target_proportion'] / brand_compar1['others_proportion']

brand_compar1_sorted = brand_compar1.sort_values(by = 'affinity', ascending = False)
print(brand_compar1_sorted.head())

"""*2) Mainstream - Retirees*"""

# filter data for the target group 2(Mainstream - Retirees)
segment2 = chips_df[(chips_df['LIFESTAGE'] == 'RETIREES') & (chips_df['PREMIUM_CUSTOMER'] == 'Mainstream')]
others2 = chips_df[~(chips_df['LIFESTAGE'] == 'RETIREES') & (chips_df['PREMIUM_CUSTOMER'] == 'Mainstream')]

# caculate brand proporation for the target group
qty_sg2 = segment2['PROD_QTY'].sum()
brand_qty_sg2 = segment2.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_sg2['target_proportion'] = brand_qty_sg2['PROD_QTY'] / qty_sg2

# caculate brand proporation for the rest of the population
qty_others2 = others2['PROD_QTY'].sum()
brand_qty_others2 = others2.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_others2['others_proportion'] = brand_qty_others2['PROD_QTY'] / qty_others2

# compare proporations
brand_compar2 = pd.merge(brand_qty_sg2[['BRAND', 'target_proportion']],
                         brand_qty_others2[['BRAND', 'others_proportion']],
                         on = 'BRAND', how = 'outer').fillna(0)
brand_compar2['affinity'] = brand_compar2['target_proportion'] / brand_compar2['others_proportion']

brand_compar2_sorted = brand_compar2.sort_values(by = 'affinity', ascending = False)
print(brand_compar2_sorted.head())

"""*3) Mainstream - Young Singles/Couples*"""

# filter data for the target group 3(Mainstream - Young Singles/Couples)
segment3 = chips_df[(chips_df['LIFESTAGE'] == 'YOUNG SINGLES/COUPLES') & (chips_df['PREMIUM_CUSTOMER'] == 'Mainstream')]
others3 = chips_df[~((chips_df['LIFESTAGE'] == 'YOUNG SINGLES/COUPLES') & (chips_df['PREMIUM_CUSTOMER'] == 'Mainstream'))]

# caculate brand proporation for the target group
qty_sg3 = segment3['PROD_QTY'].sum()
brand_qty_sg3 = segment3.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_sg3['target_proportion'] = brand_qty_sg3['PROD_QTY'] / qty_sg3

# caculate brand proporation for the rest of the population
qty_others3 = others3['PROD_QTY'].sum()
brand_qty_others3 = others3.groupby(['BRAND'])['PROD_QTY'].sum().reset_index()
brand_qty_others3['others_proportion'] = brand_qty_others3['PROD_QTY'] / qty_others3

# compare proporations
brand_compar3 = pd.merge(brand_qty_sg3[['BRAND', 'target_proportion']],
                         brand_qty_others3[['BRAND', 'others_proportion']],
                         on = 'BRAND', how = 'outer').fillna(0)
brand_compar3['affinity'] = brand_compar3['target_proportion'] / brand_compar3['others_proportion']

brand_compar3_sorted = brand_compar3.sort_values(by = 'affinity', ascending = False)
print(brand_compar3_sorted.head())

"""#### Insight: Budget - Older Families prefer brand Woolworths, Sunbites, and Smiths; Mainstream - Retirees  prefer brand Tyrrells, Pringles, and Doritos; Mainstream - Young Singles/Couples prefer brand Sunbites, Thins, and Woolworths.

### Analyze the Product Size Preference of the Top Customer Group Buyers

*1) Budget - Older Families:*
"""

# Calculate total quantity for segment1 and others
qty_sg1 = segment1['PROD_QTY'].sum()
qty_others1 = others1['PROD_QTY'].sum()

# Calculate proportions of preferred pack size for segment1
qty_sg1_by_pack = segment1.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_sg1_by_pack['target_proporation'] = qty_sg1_by_pack['PROD_QTY'] / qty_sg1
qty_sg1_by_pack = qty_sg1_by_pack.drop(columns='PROD_QTY')

# Calculate proportions of preferred pack size for other
qty_others1_by_pack = others1.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_others1_by_pack['others_proporation'] = qty_others1_by_pack['PROD_QTY'] / qty_others1
qty_others1_by_pack = qty_others1_by_pack.drop(columns='PROD_QTY')

# Merge the two dataframes
pack_prop = qty_sg1_by_pack.merge(qty_others1_by_pack, on='PACK_SIZE')

# Calculate affinity to pack size
pack_prop['Size Affinity'] = pack_prop['target_proporation'] / pack_prop['others_proporation']

# Sort by affinity to pack size
pack_prop = pack_prop.sort_values(by='Size Affinity', ascending=False)

print(pack_prop.head())

"""*2) Mainstream - Retirees*"""

# Calculate total quantity for segment2 and others
qty_sg2 = segment2['PROD_QTY'].sum()
qty_others2 = others2['PROD_QTY'].sum()

# Calculate proportions of preferred pack size for segment1
qty_sg2_by_pack = segment2.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_sg2_by_pack['target_proporation'] = qty_sg2_by_pack['PROD_QTY'] / qty_sg2
qty_sg2_by_pack = qty_sg2_by_pack.drop(columns='PROD_QTY')

# Calculate proportions of preferred pack size for other
qty_others2_by_pack = others2.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_others2_by_pack['others_proporation'] = qty_others2_by_pack['PROD_QTY'] / qty_others2
qty_others2_by_pack = qty_others2_by_pack.drop(columns='PROD_QTY')

# Merge the two dataframes
pack_prop = qty_sg2_by_pack.merge(qty_others2_by_pack, on='PACK_SIZE')

# Calculate affinity to pack size
pack_prop['Size Affinity'] = pack_prop['target_proporation'] / pack_prop['others_proporation']

# Sort by affinity to pack size
pack_prop = pack_prop.sort_values(by='Size Affinity', ascending=False)

print(pack_prop.head())

"""*3) Mainstream - Young Singles/Couples*"""

# Calculate total quantity for segment3 and others
qty_sg3 = segment3['PROD_QTY'].sum()
qty_others3 = others3['PROD_QTY'].sum()

# Calculate proportions of preferred pack size for segment1
qty_sg3_by_pack = segment3.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_sg3_by_pack['target_proporation'] = qty_sg3_by_pack['PROD_QTY'] / qty_sg3
qty_sg3_by_pack = qty_sg3_by_pack.drop(columns='PROD_QTY')

# Calculate proportions of preferred pack size for other
qty_others3_by_pack = others3.groupby('PACK_SIZE')['PROD_QTY'].sum().reset_index()
qty_others3_by_pack['others_proporation'] = qty_others3_by_pack['PROD_QTY'] / qty_others3
qty_others3_by_pack = qty_others3_by_pack.drop(columns='PROD_QTY')

# Merge the two dataframes
pack_prop = qty_sg3_by_pack.merge(qty_others3_by_pack, on='PACK_SIZE')

# Calculate affinity to pack size
pack_prop['Size Affinity'] = pack_prop['target_proporation'] / pack_prop['others_proporation']

# Sort by affinity to pack size
pack_prop = pack_prop.sort_values(by='Size Affinity', ascending=False)

print(pack_prop.head())

"""#### Insight: Budget - Older Families prefer pack size 160g, 200g, then 90g; Mainstream - Young Singles/Couples prefer pack size 380g, 165g, then 330g; Mainstream - Retirees prefer pack size 90g, 175g, 160g.

### Analyze the Product Flavor Preferences of the Top Customer Group Buyers

*1) Budget - Older Families:*
"""

# caculate flavor proporation for the segment1(Budget - Older Families)
qty_sg1 = segment1['PROD_QTY'].sum()
flavor_qty_sg1 = segment1.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_sg1['target_proportion'] = flavor_qty_sg1['PROD_QTY'] / qty_sg1

# caculate flavor proporation for the rest of the population
qty_others1 = others1['PROD_QTY'].sum()
flavor_qty_others1 = others1.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_others1['others_proportion'] = flavor_qty_others1['PROD_QTY'] / qty_others1

# compare proporations
flavor_compar1 = pd.merge(flavor_qty_sg1[['FLAVOR', 'target_proportion']],
                         flavor_qty_others1[['FLAVOR', 'others_proportion']],
                         on = 'FLAVOR', how = 'outer').fillna(0)
flavor_compar1['affinity'] = flavor_compar1['target_proportion'] / flavor_compar1['others_proportion']

flavor_compar1_sorted = flavor_compar1.sort_values(by = 'affinity', ascending = False)
print(flavor_compar1_sorted.head())

"""*2) Mainstream - Retirees*"""

# caculate flavor proporation for the segment2(Mainstream - Retirees)
qty_sg2 = segment2['PROD_QTY'].sum()
flavor_qty_sg2 = segment2.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_sg2['target_proportion'] = flavor_qty_sg2['PROD_QTY'] / qty_sg2

# caculate favor proporation for the rest of the population
qty_others2 = others2['PROD_QTY'].sum()
flavor_qty_others2 = others2.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_others2['others_proportion'] = flavor_qty_others2['PROD_QTY'] / qty_others2

# compare proporations
flavor_compar2 = pd.merge(flavor_qty_sg2[['FLAVOR', 'target_proportion']],
                         flavor_qty_others2[['FLAVOR', 'others_proportion']],
                         on = 'FLAVOR', how = 'outer').fillna(0)
flavor_compar2['affinity'] = flavor_compar2['target_proportion'] / flavor_compar2['others_proportion']

flavor_compar2_sorted = flavor_compar2.sort_values(by = 'affinity', ascending = False)
print(flavor_compar2_sorted.head())

"""*3) Mainstream - Young Singles/Couples*"""

# caculate flavor proporation for the segment3(Mainstream - Young Singles/Couples)
qty_sg3 = segment3['PROD_QTY'].sum()
flavor_qty_sg3 = segment3.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_sg3['target_proportion'] = flavor_qty_sg3['PROD_QTY'] / qty_sg3

# caculate favor proporation for the rest of the population
qty_others3 = others3['PROD_QTY'].sum()
flavor_qty_others3 = others3.groupby(['FLAVOR'])['PROD_QTY'].sum().reset_index()
flavor_qty_others3['others_proportion'] = flavor_qty_others3['PROD_QTY'] / qty_others3

# compare proporations
flavor_compar3 = pd.merge(flavor_qty_sg3[['FLAVOR', 'target_proportion']],
                         flavor_qty_others3[['FLAVOR', 'others_proportion']],
                         on = 'FLAVOR', how = 'outer').fillna(0)
flavor_compar3['affinity'] = flavor_compar3['target_proportion'] / flavor_compar3['others_proportion']

flavor_compar3_sorted = flavor_compar3.sort_values(by = 'affinity', ascending = False)
print(flavor_compar3_sorted.head())

"""#### Insight: Budget - Older Families prefer Barbecue, Barbecue, Sauce flavors; Mainstream - Young Singles/Couples prefer Mustard, Bolognese, Sauce flabors; Mainstream - Retirees prefer Chili, Chives, Garlic flavors.

#### To analyze further why these 3 customer segments contributed to the largest amount & porporation of chips' sales, see 1) the porporation of all kinds of customers; 2) the purchase amount of chips among all kinds of customers OR unit chips' sales among all kinds of customers. 3) the unit price of product.

#### 1) The porporation of all kinds of customers
"""

# Calculate number of unique customers by LIFESTAGE and PREMIUM_CUSTOMER
cust = chips_df.groupby(['PREMIUM_CUSTOMER', 'LIFESTAGE'])['LYLTY_CARD_NBR'].nunique().reset_index()
cust.columns = ['LIFESTAGE', 'PREMIUM_CUSTOMER', 'CUSTOMERS']

# Sort by the number of customers
cust = cust.sort_values(by = 'CUSTOMERS', ascending = False)

# Calculate proportion of customers
total_cust = cust['CUSTOMERS'].sum()
cust['Proporation'] = cust['CUSTOMERS'] / total_cust
cust.head()

plt.figure(figsize=(6, 4))
# Using seaborn's catplot to create a bar plot
g = sns.catplot(
    data=cust,
    x='PREMIUM_CUSTOMER', y='Proporation', hue='LIFESTAGE',
    kind='bar', height=6, aspect=2
)

g.set_axis_labels("Lifestage", "Proportion of Total Sales")
g.fig.suptitle('Proportion of Customers by Lifestage and Premium Customer', fontsize=16)
g.set_xticklabels(rotation=90)

# Adding text labels with proportion percentages
for ax in g.axes.flat:
    for p in ax.patches:
      if p.get_height() > 0:
        ax.annotate(f'{p.get_height():.2%}', (p.get_x() + p.get_width() / 2., p.get_height()),
                    ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),
                    textcoords='offset points')

plt.show()

"""#### Insight: There are more Mainstream - Young Singles/Couples and Mainstream - Retirees buy chips, but this is not a major chips' sales driver for the Budget - Older families segment.

#### 2) Unit sales among all kinds of customers
"""

# Calculate the average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
avg_units = chips_df.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER']).agg(
    {'PROD_QTY': 'sum', 'LYLTY_CARD_NBR': 'nunique'}
).reset_index()

# Calculate the average units per customer
avg_units['AVG'] = avg_units['PROD_QTY'] / avg_units['LYLTY_CARD_NBR']

# Order by average units (descending)
avg_units = avg_units.sort_values(by='AVG', ascending=False)
avg_units.head()

plt.figure(figsize=(5, 4))
sns.barplot(data = avg_units, x='LIFESTAGE', y='AVG', hue='PREMIUM_CUSTOMER', dodge=True)
plt.title('Average Units per Customer by Lifestage and Premium Customer', fontsize=16)
plt.xlabel('Lifestage')
plt.ylabel('Avg units per customer')
plt.xticks(rotation=90)
plt.legend(title='Premium Customer')
plt.show()

"""#### Insight: Older Families & Young Families buy more chips per customer.

#### 3)Unique price
"""

# Calculate the total units and total sales by LIFESTAGE and PREMIUM_CUSTOMER
unit_price = chips_df.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER']).agg(
    {'PROD_QTY': 'sum', 'TOT_SALES': 'sum'}
).reset_index()

# Calculate the unit price
unit_price['Unit_Price'] = unit_price['TOT_SALES'] / unit_price['PROD_QTY']

# Order by unit_price
unit_price = unit_price.sort_values(by='Unit_Price', ascending=False)
unit_price.head()

plt.figure(figsize=(5, 4))
sns.barplot(data = unit_price, x = 'LIFESTAGE', y = 'Unit_Price', hue = 'PREMIUM_CUSTOMER', dodge = True)
plt.title('Unit Price by Lifestage and Premium Customer', fontsize=16)
plt.xlabel('Lifestage')
plt.xticks(rotation = 90)
plt.legend(title = 'Premium Customer')
plt.show()

"""#### Insight: Young & Midage singles and couples in Mainstream are more willing to pay more per chips than in Budget and Premium segments.

### Frequency of Customer Categories
"""

plt.figure(figsize=(4, 2))
sns.histplot(chips_df, x='PREMIUM_CUSTOMER')
plt.title("Count of Customer Categories")
plt.ylabel('Frequency')
plt.xlabel('Customer Categories')

"""### Frequency of Customer Lifestage

### Analyze the Package Size of Products
"""

# Count of package size
sum_size = chips_df['PACK_SIZE'].value_counts()
sum_size.head()

plt.figure(figsize=(4, 4))
size_order = chips_df['PACK_SIZE'].value_counts().index

sns.countplot(chips_df, x='PACK_SIZE', order = size_order)
plt.title("Frequency of Purchased Chips' Package Size")
plt.xticks(rotation=90)

plt.show()

"""#### Insight: For all customers, the most popular chips package size is 175g, then is 150g.

### Analyze the Brands
"""

# Count of brands
sum_brand = chips_df['BRAND'].value_counts()
sum_brand

# Calculate the frequency of each brand and sort them
plt.figure(figsize=(6, 4))
brand_order = sum_brand.index

sns.countplot(chips_df, x='BRAND',order=brand_order)
plt.title("Frequency of Chips's Brand")
plt.xticks(rotation=90)

plt.show()

"""#### Insight: For all customers, Smiths is the most popular chips' brand; second is Doritos, third is Thins."""

plt.figure(figsize=(5, 3))
sns.histplot(data=chips_df, y='LIFESTAGE')
plt.title('Frequency of Customer Lifestage')
plt.xlabel('Frequency')

"""#### Insight: 'New families' customers purchased chips the least among all the Customer Lifestage groups.

### Analyze of Flavor
"""

# Count of flavor
sum_flavor = chips_df['FLAVOR'].value_counts()
sum_flavor

plt.figure(figsize=(10, 4))
flavor_order = sum_flavor.index

sns.countplot(chips_df, x='FLAVOR',order=flavor_order)
plt.title("Frequency of Chips's Flavor")
plt.xticks(rotation=90)

plt.show()

"""#### Insight: Too much unknown prefered flavors for all the customers, the analysis of flavor might be biased.

### Trend and Insight (for Chips)
"""

chips_sales_sum = chips_df['TOT_SALES'].sum()
chips_sales_mean = chips_df['TOT_SALES'].mean()
chips_sales_median = chips_df['TOT_SALES'].median()
print(f"Chips' Total Sales Sum: {chips_sales_sum}")
print(f"Chips' Total Sales Mean: {chips_sales_mean}")
print(f"Chips' Total Sales Median: {chips_sales_median}")

# Highest sales by Lifestage
chips_lifestage = chips_df.groupby('LIFESTAGE')['TOT_SALES'].sum().sort_values(ascending = False)
print(f"Chips' Total Sales by Lifestage: \n {chips_lifestage}.")

# Highest sales by Customer Categories
chips_cust = chips_df.groupby('PREMIUM_CUSTOMER')['TOT_SALES'].sum().sort_values(ascending = False)
print(f"Chips' Total Sales by Customer Categories: \n {chips_cust}.")

# Highest sales by Customer Categories & Lifestage
cust_sales = chips_df.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['TOT_SALES'].sum().sort_values(ascending = False)
print(f"Chips' Total Sales by Customer Categories & Lifestage: \n {cust_sales}.")

# Highest sales by Product Categories
chips_prod = chips_df.groupby('PROD_NAME')['TOT_SALES'].sum().sort_values(ascending = False)
print(f"Chips' Total Sales by Product Categories: \n {chips_prod}\n\n")

top_chips_names = chips_prod.head(10).index.to_list()
count_chips_prod = chips_prod.count()
print(f"We are selling {count_chips_prod} kinds of chip products.")

# Print each product name on a new line
print("For all customers, our Top 10 Best Selling Chips are:")
for name in top_chips_names:
    print(name)

"""### Recommendation:
1. In order to improve sales of chips, for customer category, we should target Mainstream Customer in priority; for customer lifestage, we should target older customers in priority (OLDER SINGLES/COUPLES, OLDER FAMILIES and RETIREES). For smaller customer segments, we should target Budget - Older Families, Mainstream - Retirees, and Mainstream - Young Singles/Couples.

- Specially, Mainstream - Young Singles/Couples not only contributes a lot to our sales, but also takes up the largest proporation of our amount of customers.

- Mainstream - Young & Midage singles and couples are more willing to pay more per chips, which is indicative of impulse buying behaviour. When we lay out chips in the store, we can consider put more chips in the discretionary space that favored by them.

2. When it comes to chips brands selection, For all customers, Smiths is the most popular chips' brand; second is Doritos, third is Thins. For the top target customers, Woodworths, Sunbites, and Smiths are the most popular. Mainstream - Young Singles/Couples prefer brand Tyrrells, Pringles, and Doritos.

3. When is comes to pack size, 160g(medium-sized) and 90g(small-sized) is most favored by 2 of our target customer groups. For Mainstream - Young Singles/Couples, they prefer medium & large-sized chips. For all customers, 175g(medium to large-sized) & 170g(medium to large-sized) are the most popular size. In general, medium & large-sized chips seems more popular.

4. When it comes to favor, for the target customer groups, Budget - Older Families prefer Barbecue, Barbecue, Sauce flavors; Mainstream - Young Singles/Couples prefer Mustard, Bolognese, Sauce flabors; Mainstream - Retirees prefer Chili, Chives, Garlic flavors.


"""

import matplotlib.pyplot as plt

def convert_to_pdf_matplotlib(input_file, output_pdf):
    with open(input_file, 'r') as python_file:
        content = python_file.read()
        fig, ax = plt.subplots()
        ax.text(0.1, 0.5, content, wrap=True, fontsize=12)
        ax.axis('off')

        plt.savefig(output_pdf, format='pdf')

# Example usage:
convert_to_pdf_matplotlib('forage_quantium_da_test1.py', 'forage_quantium_da_test1.pdf')
print("PDF is Saved Successfully")